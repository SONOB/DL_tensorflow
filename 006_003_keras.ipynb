{"cells":[{"cell_type":"code","source":["import numpy as np\n","import urllib.request\n","from tensorflow.keras.utils import to_categorical\n","\n","# 데이터 로드\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\", filename=\"shake.txt\")\n","\n","f = open('shake.txt', 'rb')\n","sentences = []\n","for sentence in f: # 데이터로부터 한 줄씩 읽는다.\n","    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거한다.\n","    sentence = sentence.lower() # 소문자화.\n","    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n","    if len(sentence) > 0:\n","        sentences.append(sentence)\n","f.close()"],"metadata":{"id":"VBhM9t2UzeaD","executionInfo":{"status":"ok","timestamp":1711677863059,"user_tz":-540,"elapsed":618,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["sentences[:5]"],"metadata":{"id":"84nwQmKyzf0h","executionInfo":{"status":"ok","timestamp":1711677865484,"user_tz":-540,"elapsed":3,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"7c923e12-998d-4924-e30e-ed8eea7b1c14","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['first citizen:',\n"," 'before we proceed any further, hear me speak.',\n"," 'all:',\n"," 'speak, speak.',\n"," 'first citizen:']"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["total_data = ' '.join(sentences)\n","print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"],"metadata":{"id":"0WsEVBLBzhJY","executionInfo":{"status":"ok","timestamp":1711677867066,"user_tz":-540,"elapsed":3,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"bc68199c-a56c-4f78-99bd-fc01dafbef0a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["문자열의 길이 또는 총 문자의 개수: 1108166\n"]}]},{"cell_type":"code","source":["print(total_data[:200])"],"metadata":{"id":"N-4aDIGtzjFA","executionInfo":{"status":"ok","timestamp":1711677869138,"user_tz":-540,"elapsed":3,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"805f98e8-fa0d-438e-ab10-a57e0aa2bc43","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["first citizen: before we proceed any further, hear me speak. all: speak, speak. first citizen: you are all resolved rather to die than to famish? all: resolved. resolved. first citizen: first, you kno\n"]}]},{"cell_type":"code","source":["char_vocab = sorted(list(set(total_data)))\n","vocab_size = len(char_vocab)\n","print ('문자 집합의 크기 : {}'.format(vocab_size))"],"metadata":{"id":"bFqdC9mczkSI","executionInfo":{"status":"ok","timestamp":1711677894976,"user_tz":-540,"elapsed":461,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"63f56846-e26c-4161-ce0c-c4dbb20d0f59","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["문자 집합의 크기 : 38\n"]}]},{"cell_type":"code","source":["# 문자에 고유한 정수 부여\n","char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n","print('문자 집합 :',char_to_index)"],"metadata":{"id":"27iw4LJzzmIw","executionInfo":{"status":"ok","timestamp":1711677940653,"user_tz":-540,"elapsed":377,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"ea6ee858-1e36-44c8-e7ad-4443158db7a0","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["문자 집합 : {' ': 0, '!': 1, '$': 2, '&': 3, \"'\": 4, ',': 5, '-': 6, '.': 7, '3': 8, ':': 9, ';': 10, '?': 11, 'a': 12, 'b': 13, 'c': 14, 'd': 15, 'e': 16, 'f': 17, 'g': 18, 'h': 19, 'i': 20, 'j': 21, 'k': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'q': 28, 'r': 29, 's': 30, 't': 31, 'u': 32, 'v': 33, 'w': 34, 'x': 35, 'y': 36, 'z': 37}\n"]}]},{"cell_type":"code","source":["index_to_char = {}\n","for key, value in char_to_index.items():\n","    index_to_char[value] = key"],"metadata":{"id":"Mtg2-xz-znaw","executionInfo":{"status":"ok","timestamp":1711679106212,"user_tz":-540,"elapsed":379,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["seq_length = 60\n","\n","# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n","n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n","print ('샘플의 수 : {}'.format(n_samples))"],"metadata":{"id":"h_adH_70zqQI","executionInfo":{"status":"ok","timestamp":1711679164497,"user_tz":-540,"elapsed":649,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"826084a7-f83f-4ee6-f4b4-caca896eef4a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플의 수 : 18469\n"]}]},{"cell_type":"code","source":["train_X = []\n","train_y = []\n","\n","for i in range(n_samples):\n","    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 pick.\n","    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n","\n","    # 정수 인코딩\n","    X_encoded = [char_to_index[c] for c in X_sample]\n","    train_X.append(X_encoded)\n","\n","    # 오른쪽으로 1칸 쉬프트\n","    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n","    y_encoded = [char_to_index[c] for c in y_sample]\n","    train_y.append(y_encoded)"],"metadata":{"id":"lIvYiRDJzsF5","executionInfo":{"status":"ok","timestamp":1711679182460,"user_tz":-540,"elapsed":597,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["print('X 데이터의 첫번째 샘플 :',train_X[0])\n","print('y 데이터의 첫번째 샘플 :',train_y[0])\n","print('-'*50)\n","print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n","print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"],"metadata":{"id":"ywhjenqBz253","executionInfo":{"status":"ok","timestamp":1711679191045,"user_tz":-540,"elapsed":3,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"629d191c-2109-4fb2-c60c-0788448d8cf2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["X 데이터의 첫번째 샘플 : [17, 20, 29, 30, 31, 0, 14, 20, 31, 20, 37, 16, 25, 9, 0, 13, 16, 17, 26, 29, 16, 0, 34, 16, 0, 27, 29, 26, 14, 16, 16, 15, 0, 12, 25, 36, 0, 17, 32, 29, 31, 19, 16, 29, 5, 0, 19, 16, 12, 29, 0, 24, 16, 0, 30, 27, 16, 12, 22, 7]\n","y 데이터의 첫번째 샘플 : [20, 29, 30, 31, 0, 14, 20, 31, 20, 37, 16, 25, 9, 0, 13, 16, 17, 26, 29, 16, 0, 34, 16, 0, 27, 29, 26, 14, 16, 16, 15, 0, 12, 25, 36, 0, 17, 32, 29, 31, 19, 16, 29, 5, 0, 19, 16, 12, 29, 0, 24, 16, 0, 30, 27, 16, 12, 22, 7, 0]\n","--------------------------------------------------\n","X 데이터의 첫번째 샘플 디코딩 : ['f', 'i', 'r', 's', 't', ' ', 'c', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'b', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.']\n","y 데이터의 첫번째 샘플 디코딩 : ['i', 'r', 's', 't', ' ', 'c', 'i', 't', 'i', 'z', 'e', 'n', ':', ' ', 'b', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', ' ']\n"]}]},{"cell_type":"code","source":["print(train_X[1])\n","print(train_y[1])"],"metadata":{"id":"j-izD_ySz4cI","executionInfo":{"status":"ok","timestamp":1711679194937,"user_tz":-540,"elapsed":2,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"9126da4b-8245-4fb6-9a95-9093cb8f6623","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 12, 23, 23, 9, 0, 30, 27, 16, 12, 22, 5, 0, 30, 27, 16, 12, 22, 7, 0, 17, 20, 29, 30, 31, 0, 14, 20, 31, 20, 37, 16, 25, 9, 0, 36, 26, 32, 0, 12, 29, 16, 0, 12, 23, 23, 0, 29, 16, 30, 26, 23, 33, 16, 15, 0, 29, 12, 31, 19]\n","[12, 23, 23, 9, 0, 30, 27, 16, 12, 22, 5, 0, 30, 27, 16, 12, 22, 7, 0, 17, 20, 29, 30, 31, 0, 14, 20, 31, 20, 37, 16, 25, 9, 0, 36, 26, 32, 0, 12, 29, 16, 0, 12, 23, 23, 0, 29, 16, 30, 26, 23, 33, 16, 15, 0, 29, 12, 31, 19, 16]\n"]}]},{"cell_type":"code","source":["train_X = to_categorical(train_X)\n","train_y = to_categorical(train_y)\n","\n","print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n","print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"],"metadata":{"id":"VbVG5yipz6w4","executionInfo":{"status":"ok","timestamp":1711679210595,"user_tz":-540,"elapsed":630,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"e0f11e6f-12b7-46e1-fa6e-09c0c4effa6d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["train_X의 크기(shape) : (18469, 60, 38)\n","train_y의 크기(shape) : (18469, 60, 38)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n","\n","hidden_units = 256\n","\n","model = Sequential()\n","model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n","model.add(LSTM(hidden_units, return_sequences=True))\n","model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(train_X, train_y, epochs=100, verbose=2)"],"metadata":{"id":"SGb_1XzHz80v","executionInfo":{"status":"ok","timestamp":1711681957742,"user_tz":-540,"elapsed":567361,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"18519918-ae9a-4c24-8ee0-94ddd2f22f94","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","578/578 - 9s - loss: 2.3847 - accuracy: 0.3217 - 9s/epoch - 16ms/step\n","Epoch 2/100\n","578/578 - 5s - loss: 1.8773 - accuracy: 0.4412 - 5s/epoch - 9ms/step\n","Epoch 3/100\n","578/578 - 5s - loss: 1.6895 - accuracy: 0.4923 - 5s/epoch - 9ms/step\n","Epoch 4/100\n","578/578 - 5s - loss: 1.5756 - accuracy: 0.5230 - 5s/epoch - 9ms/step\n","Epoch 5/100\n","578/578 - 5s - loss: 1.5014 - accuracy: 0.5423 - 5s/epoch - 9ms/step\n","Epoch 6/100\n","578/578 - 5s - loss: 1.4481 - accuracy: 0.5556 - 5s/epoch - 9ms/step\n","Epoch 7/100\n","578/578 - 5s - loss: 1.4084 - accuracy: 0.5658 - 5s/epoch - 9ms/step\n","Epoch 8/100\n","578/578 - 5s - loss: 1.3759 - accuracy: 0.5738 - 5s/epoch - 9ms/step\n","Epoch 9/100\n","578/578 - 5s - loss: 1.3490 - accuracy: 0.5806 - 5s/epoch - 9ms/step\n","Epoch 10/100\n","578/578 - 5s - loss: 1.3254 - accuracy: 0.5866 - 5s/epoch - 9ms/step\n","Epoch 11/100\n","578/578 - 5s - loss: 1.3044 - accuracy: 0.5927 - 5s/epoch - 8ms/step\n","Epoch 12/100\n","578/578 - 5s - loss: 1.2850 - accuracy: 0.5973 - 5s/epoch - 9ms/step\n","Epoch 13/100\n","578/578 - 5s - loss: 1.2679 - accuracy: 0.6018 - 5s/epoch - 9ms/step\n","Epoch 14/100\n","578/578 - 5s - loss: 1.2515 - accuracy: 0.6062 - 5s/epoch - 9ms/step\n","Epoch 15/100\n","578/578 - 5s - loss: 1.2357 - accuracy: 0.6105 - 5s/epoch - 8ms/step\n","Epoch 16/100\n","578/578 - 5s - loss: 1.2206 - accuracy: 0.6145 - 5s/epoch - 9ms/step\n","Epoch 17/100\n","578/578 - 5s - loss: 1.2063 - accuracy: 0.6185 - 5s/epoch - 9ms/step\n","Epoch 18/100\n","578/578 - 5s - loss: 1.1921 - accuracy: 0.6229 - 5s/epoch - 9ms/step\n","Epoch 19/100\n","578/578 - 5s - loss: 1.1785 - accuracy: 0.6266 - 5s/epoch - 9ms/step\n","Epoch 20/100\n","578/578 - 5s - loss: 1.1648 - accuracy: 0.6305 - 5s/epoch - 9ms/step\n","Epoch 21/100\n","578/578 - 5s - loss: 1.1519 - accuracy: 0.6340 - 5s/epoch - 9ms/step\n","Epoch 22/100\n","578/578 - 5s - loss: 1.1388 - accuracy: 0.6383 - 5s/epoch - 9ms/step\n","Epoch 23/100\n","578/578 - 5s - loss: 1.1260 - accuracy: 0.6420 - 5s/epoch - 9ms/step\n","Epoch 24/100\n","578/578 - 5s - loss: 1.1133 - accuracy: 0.6459 - 5s/epoch - 9ms/step\n","Epoch 25/100\n","578/578 - 5s - loss: 1.1012 - accuracy: 0.6495 - 5s/epoch - 8ms/step\n","Epoch 26/100\n","578/578 - 5s - loss: 1.0889 - accuracy: 0.6529 - 5s/epoch - 9ms/step\n","Epoch 27/100\n","578/578 - 5s - loss: 1.0767 - accuracy: 0.6571 - 5s/epoch - 9ms/step\n","Epoch 28/100\n","578/578 - 5s - loss: 1.0647 - accuracy: 0.6603 - 5s/epoch - 9ms/step\n","Epoch 29/100\n","578/578 - 5s - loss: 1.0536 - accuracy: 0.6634 - 5s/epoch - 8ms/step\n","Epoch 30/100\n","578/578 - 5s - loss: 1.0420 - accuracy: 0.6674 - 5s/epoch - 9ms/step\n","Epoch 31/100\n","578/578 - 5s - loss: 1.0310 - accuracy: 0.6709 - 5s/epoch - 9ms/step\n","Epoch 32/100\n","578/578 - 5s - loss: 1.0196 - accuracy: 0.6743 - 5s/epoch - 8ms/step\n","Epoch 33/100\n","578/578 - 5s - loss: 1.0088 - accuracy: 0.6779 - 5s/epoch - 9ms/step\n","Epoch 34/100\n","578/578 - 5s - loss: 0.9984 - accuracy: 0.6811 - 5s/epoch - 9ms/step\n","Epoch 35/100\n","578/578 - 5s - loss: 0.9877 - accuracy: 0.6844 - 5s/epoch - 9ms/step\n","Epoch 36/100\n","578/578 - 5s - loss: 0.9785 - accuracy: 0.6871 - 5s/epoch - 8ms/step\n","Epoch 37/100\n","578/578 - 5s - loss: 0.9683 - accuracy: 0.6904 - 5s/epoch - 9ms/step\n","Epoch 38/100\n","578/578 - 5s - loss: 0.9582 - accuracy: 0.6935 - 5s/epoch - 9ms/step\n","Epoch 39/100\n","578/578 - 5s - loss: 0.9492 - accuracy: 0.6964 - 5s/epoch - 9ms/step\n","Epoch 40/100\n","578/578 - 5s - loss: 0.9402 - accuracy: 0.6993 - 5s/epoch - 9ms/step\n","Epoch 41/100\n","578/578 - 5s - loss: 0.9312 - accuracy: 0.7026 - 5s/epoch - 9ms/step\n","Epoch 42/100\n","578/578 - 5s - loss: 0.9225 - accuracy: 0.7050 - 5s/epoch - 9ms/step\n","Epoch 43/100\n","578/578 - 5s - loss: 0.9136 - accuracy: 0.7078 - 5s/epoch - 8ms/step\n","Epoch 44/100\n","578/578 - 5s - loss: 0.9056 - accuracy: 0.7100 - 5s/epoch - 8ms/step\n","Epoch 45/100\n","578/578 - 5s - loss: 0.8979 - accuracy: 0.7125 - 5s/epoch - 9ms/step\n","Epoch 46/100\n","578/578 - 5s - loss: 0.8903 - accuracy: 0.7147 - 5s/epoch - 9ms/step\n","Epoch 47/100\n","578/578 - 5s - loss: 0.8820 - accuracy: 0.7177 - 5s/epoch - 9ms/step\n","Epoch 48/100\n","578/578 - 5s - loss: 0.8750 - accuracy: 0.7194 - 5s/epoch - 9ms/step\n","Epoch 49/100\n","578/578 - 5s - loss: 0.8685 - accuracy: 0.7217 - 5s/epoch - 9ms/step\n","Epoch 50/100\n","578/578 - 5s - loss: 0.8613 - accuracy: 0.7239 - 5s/epoch - 9ms/step\n","Epoch 51/100\n","578/578 - 5s - loss: 0.8545 - accuracy: 0.7259 - 5s/epoch - 9ms/step\n","Epoch 52/100\n","578/578 - 5s - loss: 0.8471 - accuracy: 0.7282 - 5s/epoch - 9ms/step\n","Epoch 53/100\n","578/578 - 5s - loss: 0.8414 - accuracy: 0.7295 - 5s/epoch - 8ms/step\n","Epoch 54/100\n","578/578 - 5s - loss: 0.8351 - accuracy: 0.7321 - 5s/epoch - 9ms/step\n","Epoch 55/100\n","578/578 - 5s - loss: 0.8293 - accuracy: 0.7337 - 5s/epoch - 8ms/step\n","Epoch 56/100\n","578/578 - 5s - loss: 0.8238 - accuracy: 0.7348 - 5s/epoch - 9ms/step\n","Epoch 57/100\n","578/578 - 5s - loss: 0.8170 - accuracy: 0.7370 - 5s/epoch - 9ms/step\n","Epoch 58/100\n","578/578 - 5s - loss: 0.8123 - accuracy: 0.7387 - 5s/epoch - 9ms/step\n","Epoch 59/100\n","578/578 - 5s - loss: 0.8058 - accuracy: 0.7408 - 5s/epoch - 9ms/step\n","Epoch 60/100\n","578/578 - 5s - loss: 0.8010 - accuracy: 0.7421 - 5s/epoch - 8ms/step\n","Epoch 61/100\n","578/578 - 5s - loss: 0.7963 - accuracy: 0.7436 - 5s/epoch - 9ms/step\n","Epoch 62/100\n","578/578 - 5s - loss: 0.7918 - accuracy: 0.7453 - 5s/epoch - 9ms/step\n","Epoch 63/100\n","578/578 - 5s - loss: 0.7874 - accuracy: 0.7463 - 5s/epoch - 9ms/step\n","Epoch 64/100\n","578/578 - 5s - loss: 0.7811 - accuracy: 0.7484 - 5s/epoch - 9ms/step\n","Epoch 65/100\n","578/578 - 5s - loss: 0.7783 - accuracy: 0.7485 - 5s/epoch - 9ms/step\n","Epoch 66/100\n","578/578 - 5s - loss: 0.7729 - accuracy: 0.7509 - 5s/epoch - 9ms/step\n","Epoch 67/100\n","578/578 - 5s - loss: 0.7694 - accuracy: 0.7513 - 5s/epoch - 8ms/step\n","Epoch 68/100\n","578/578 - 5s - loss: 0.7656 - accuracy: 0.7524 - 5s/epoch - 9ms/step\n","Epoch 69/100\n","578/578 - 5s - loss: 0.7592 - accuracy: 0.7549 - 5s/epoch - 8ms/step\n","Epoch 70/100\n","578/578 - 5s - loss: 0.7564 - accuracy: 0.7554 - 5s/epoch - 9ms/step\n","Epoch 71/100\n","578/578 - 5s - loss: 0.7529 - accuracy: 0.7564 - 5s/epoch - 9ms/step\n","Epoch 72/100\n","578/578 - 5s - loss: 0.7483 - accuracy: 0.7579 - 5s/epoch - 8ms/step\n","Epoch 73/100\n","578/578 - 5s - loss: 0.7451 - accuracy: 0.7587 - 5s/epoch - 9ms/step\n","Epoch 74/100\n","578/578 - 5s - loss: 0.7417 - accuracy: 0.7600 - 5s/epoch - 8ms/step\n","Epoch 75/100\n","578/578 - 5s - loss: 0.7379 - accuracy: 0.7613 - 5s/epoch - 9ms/step\n","Epoch 76/100\n","578/578 - 5s - loss: 0.7350 - accuracy: 0.7619 - 5s/epoch - 9ms/step\n","Epoch 77/100\n","578/578 - 5s - loss: 0.7313 - accuracy: 0.7626 - 5s/epoch - 9ms/step\n","Epoch 78/100\n","578/578 - 5s - loss: 0.7298 - accuracy: 0.7632 - 5s/epoch - 9ms/step\n","Epoch 79/100\n","578/578 - 5s - loss: 0.7256 - accuracy: 0.7646 - 5s/epoch - 8ms/step\n","Epoch 80/100\n","578/578 - 5s - loss: 0.7212 - accuracy: 0.7661 - 5s/epoch - 9ms/step\n","Epoch 81/100\n","578/578 - 5s - loss: 0.7189 - accuracy: 0.7666 - 5s/epoch - 8ms/step\n","Epoch 82/100\n","578/578 - 5s - loss: 0.7176 - accuracy: 0.7669 - 5s/epoch - 9ms/step\n","Epoch 83/100\n","578/578 - 5s - loss: 0.7139 - accuracy: 0.7679 - 5s/epoch - 9ms/step\n","Epoch 84/100\n","578/578 - 5s - loss: 0.7116 - accuracy: 0.7685 - 5s/epoch - 9ms/step\n","Epoch 85/100\n","578/578 - 5s - loss: 0.7090 - accuracy: 0.7693 - 5s/epoch - 9ms/step\n","Epoch 86/100\n","578/578 - 5s - loss: 0.7062 - accuracy: 0.7701 - 5s/epoch - 8ms/step\n","Epoch 87/100\n","578/578 - 5s - loss: 0.7034 - accuracy: 0.7711 - 5s/epoch - 9ms/step\n","Epoch 88/100\n","578/578 - 5s - loss: 0.7007 - accuracy: 0.7719 - 5s/epoch - 8ms/step\n","Epoch 89/100\n","578/578 - 5s - loss: 0.6983 - accuracy: 0.7729 - 5s/epoch - 9ms/step\n","Epoch 90/100\n","578/578 - 5s - loss: 0.6955 - accuracy: 0.7733 - 5s/epoch - 8ms/step\n","Epoch 91/100\n","578/578 - 5s - loss: 0.6955 - accuracy: 0.7733 - 5s/epoch - 8ms/step\n","Epoch 92/100\n","578/578 - 5s - loss: 0.6922 - accuracy: 0.7747 - 5s/epoch - 9ms/step\n","Epoch 93/100\n","578/578 - 5s - loss: 0.6896 - accuracy: 0.7751 - 5s/epoch - 8ms/step\n","Epoch 94/100\n","578/578 - 5s - loss: 0.6871 - accuracy: 0.7758 - 5s/epoch - 9ms/step\n","Epoch 95/100\n","578/578 - 5s - loss: 0.6845 - accuracy: 0.7766 - 5s/epoch - 8ms/step\n","Epoch 96/100\n","578/578 - 5s - loss: 0.6841 - accuracy: 0.7765 - 5s/epoch - 9ms/step\n","Epoch 97/100\n","578/578 - 5s - loss: 0.6826 - accuracy: 0.7767 - 5s/epoch - 8ms/step\n","Epoch 98/100\n","578/578 - 5s - loss: 0.6773 - accuracy: 0.7788 - 5s/epoch - 8ms/step\n","Epoch 99/100\n","578/578 - 5s - loss: 0.6784 - accuracy: 0.7782 - 5s/epoch - 9ms/step\n","Epoch 100/100\n","578/578 - 5s - loss: 0.6767 - accuracy: 0.7786 - 5s/epoch - 8ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ce7416fed40>"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["def sentence_generation(model, length):\n","    # 문자에 대한 랜덤한 정수 생성\n","    ix = [np.random.randint(vocab_size)]\n","\n","    # 랜덤한 정수로부터 맵핑되는 문자 생성\n","    y_char = [index_to_char[ix[-1]]]\n","    print(ix[-1],'번 문자', y_char[-1],'로 예측을 시작!')\n","\n","    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n","    X = np.zeros((1, length, vocab_size))\n","\n","    for i in range(length):\n","        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n","        X[0][i][ix[-1]] = 1\n","        print(index_to_char[ix[-1]], end=\"\")\n","        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n","        y_char.append(index_to_char[ix[-1]])\n","    return ('').join(y_char)\n"],"metadata":{"id":"7oPJjv_Sz-UK","executionInfo":{"status":"ok","timestamp":1711682146834,"user_tz":-540,"elapsed":468,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["result = sentence_generation(model, 100)\n","print(result)"],"metadata":{"id":"GXxL38N50ALp","executionInfo":{"status":"ok","timestamp":1711682158273,"user_tz":-540,"elapsed":9779,"user":{"displayName":"SONOB Mr.","userId":"06334171337523615972"}},"outputId":"9565df8f-bd70-4369-9991-fd8992eba4da","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["28 번 문자 q 로 예측을 시작!\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 58ms/step\n","1/1 [==============================] - 0s 53ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 49ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","queen elizabeth: o thou hast surp acces on our manner i'll disease you speak of care, thou shalt awak\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pNKSN2OjJ1bf"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1711608615952}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}